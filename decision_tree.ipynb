{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-02T10:15:12.660040Z",
     "start_time": "2025-09-02T10:15:11.709014Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import joblib\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:46:36.524307Z",
     "start_time": "2025-08-18T08:46:36.519255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_temp_chill():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def get_temp_boiler():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def GPXX_check():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def room_check():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def get_occupation():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def get_elec_consumption():\n",
    "    temp = 2\n",
    "    return temp\n",
    "def get_gaz_consumption():\n",
    "    temp = 2\n",
    "    return temp"
   ],
   "id": "2aeb4268a6e0d054",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:02.897169Z",
     "start_time": "2025-08-18T08:23:02.890022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class node():\n",
    "    def __init__(self,type,text,options,on_action=False):\n",
    "        self.type=type\n",
    "        self.text=text\n",
    "        self.options =options\n",
    "        self.on_action=on_action\n",
    "    def next(self,model_output,clf,tree):\n",
    "        next_ = []\n",
    "        labels = [opt[\"next\"] for opt in main_node.options]\n",
    "        print(clf.classes_)\n",
    "        print(labels)\n",
    "        for i in range(len(clf.classes_)):\n",
    "            if clf.classes_[i] in labels:\n",
    "                next_.append(model_output[i])\n",
    "        print(next_)\n",
    "        pred_class = labels[next_.index(max(next_))]\n",
    "        confidence = max(next_)\n",
    "        print(confidence)\n",
    "        threshold = 1/len(clf.classes_)\n",
    "        print(threshold)\n",
    "        if confidence<threshold:\n",
    "            self.type=\"handoff\"\n",
    "            self.text=\"problem due to bad comprehension you can either repeat or call that number :\"\n",
    "            self.options = self.options.copy()\n",
    "            self.on_action=False\n",
    "        if confidence>threshold:\n",
    "            for i in tree[\"nodes\"].keys():\n",
    "                if i == pred_class:\n",
    "                    self.type=tree[\"nodes\"][i][\"type\"]\n",
    "                    self.text= tree[\"nodes\"][i][\"text\"]\n",
    "                    self.options = tree[\"nodes\"][i][\"options\"]\n",
    "                    self.on_action=tree[\"nodes\"][i][\"on_action\"]"
   ],
   "id": "ade17faf299e79a4",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:18:05.331896Z",
     "start_time": "2025-09-02T11:18:05.183352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "file_path = \"./dataset_LLM.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(df)"
   ],
   "id": "d7d269d98670af20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text            intent\n",
      "0                              je veux réparer            fixing\n",
      "1                 j ai besoin d une réparation            fixing\n",
      "2                       service de maintenance            fixing\n",
      "3                   un technicien pour réparer            fixing\n",
      "4          besoin d une intervention technique            fixing\n",
      "..                                         ...               ...\n",
      "685                              sonde CHWS HS  chill_production\n",
      "686                              sonde CHWR HS  chill_production\n",
      "687  séquence de démarrage production froid KO  chill_production\n",
      "688           priorité des chillers incorrecte  chill_production\n",
      "689            alternance des chillers bloquée  chill_production\n",
      "\n",
      "[690 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TFIDF",
   "id": "b45a302a40f3d1cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:05.755673Z",
     "start_time": "2025-08-18T08:23:05.735136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Création du vectoriseur TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=1)\n",
    "\n",
    "# Transformation du texte\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "y = df[\"intent\"]\n",
    "print(\"Shape des vecteurs :\", X.shape)  # nb_exemples x nb_features\n",
    "print(\"Exemple de features :\", vectorizer.get_feature_names_out()[:10])\n"
   ],
   "id": "207c84ed8aa49413",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des vecteurs : (690, 2632)\n",
      "Exemple de features : ['101' '101 maintenant' '101 temperature' '101 valeur'\n",
      " '101 valeur actuelle' '1er' '1er étage' '203' '203 24h' '24h']\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:06.775662Z",
     "start_time": "2025-08-18T08:23:06.468805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Création et entraînement du modèle\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "joblib.dump(clf, \"modele_LLM_tfidf.pkl\")\n",
    "print(classification_report(y_test, y_pred,zero_division=0))\n",
    "print(\"Classes :\", clf.classes_)"
   ],
   "id": "6eedd2bb42f3f4e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Hotel_info       0.54      1.00      0.70        21\n",
      "             acceuil       1.00      0.11      0.20         9\n",
      "       boiler_fixing       0.54      0.83      0.66        23\n",
      "    chill_production       0.75      0.46      0.57        13\n",
      "      chiller_fixing       0.65      0.79      0.71        19\n",
      "        cogen_fixing       0.51      0.91      0.66        23\n",
      "              fixing       0.00      0.00      0.00         9\n",
      "     get_consumption       0.80      0.44      0.57         9\n",
      "get_elec_consumption       0.67      0.22      0.33         9\n",
      " get_gaz_consumption       1.00      1.00      1.00         9\n",
      "      get_occupation       1.00      0.33      0.50         9\n",
      "     heat_production       1.00      0.11      0.20         9\n",
      "               rooms       0.76      0.89      0.82        18\n",
      "         temp_boiler       1.00      0.67      0.80         9\n",
      "          temp_chill       1.00      0.56      0.71         9\n",
      "         ventilation       1.00      0.78      0.88         9\n",
      "\n",
      "            accuracy                           0.66       207\n",
      "           macro avg       0.76      0.57      0.58       207\n",
      "        weighted avg       0.71      0.66      0.62       207\n",
      "\n",
      "Classes : ['Hotel_info' 'acceuil' 'boiler_fixing' 'chill_production'\n",
      " 'chiller_fixing' 'cogen_fixing' 'fixing' 'get_consumption'\n",
      " 'get_elec_consumption' 'get_gaz_consumption' 'get_occupation'\n",
      " 'heat_production' 'rooms' 'temp_boiler' 'temp_chill' 'ventilation']\n"
     ]
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:07.895583Z",
     "start_time": "2025-08-18T08:23:07.890112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prediction(input):\n",
    "    X_new = vectorizer.transform(input)\n",
    "    proba = clf.predict_proba(X_new)[0]\n",
    "    return proba\n",
    "\n",
    "test = [\"comment va la ventilation ?\"]\n",
    "proba = prediction(test)\n",
    "print(proba)\n",
    "pred_class = clf.classes_[proba.argmax()]\n",
    "confidence = proba.max()\n",
    "print(f\"Intent prédit : {pred_class} (confiance {confidence:.2f})\")\n",
    "\n"
   ],
   "id": "db10322418f840d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04430576 0.02676999 0.0536924  0.04117054 0.03909048 0.05904285\n",
      " 0.0255774  0.02062695 0.0250736  0.02122393 0.02621931 0.02876818\n",
      " 0.06044408 0.0227571  0.0227357  0.48250174]\n",
      "Intent prédit : ventilation (confiance 0.48)\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# transformer",
   "id": "1dfd6373dd367b36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:17.346689Z",
     "start_time": "2025-08-18T08:23:08.896525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "X_emb = model.encode(df[\"text\"], convert_to_numpy=True, normalize_embeddings=True)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"intent\"])\n"
   ],
   "id": "6e7523666f59a37e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugom\\OneDrive\\Documents\\Git_Stage_2025_ZMH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:17.615848Z",
     "start_time": "2025-08-18T08:23:17.353699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Création et entraînement du modèle\n",
    "clf_T = LogisticRegression(max_iter=2000)\n",
    "clf_T.fit(X_emb, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_emb, y, stratify=y, test_size=0.3, random_state=42)\n",
    "clf_T.fit(X_train, y_train)\n",
    "y_pred = clf_T.predict(X_test)\n",
    "joblib.dump(clf_T, \"modele_LLM_T.pkl\")\n",
    "\n",
    "print(classification_report(y_test, y_pred,zero_division=0))\n",
    "print(\"Classes :\", le.classes_)"
   ],
   "id": "5ee1ae383233046e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        21\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.66      0.83      0.73        23\n",
      "           3       0.80      0.62      0.70        13\n",
      "           4       0.74      0.74      0.74        19\n",
      "           5       0.61      0.83      0.70        23\n",
      "           6       0.71      0.56      0.62         9\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.86      0.67      0.75         9\n",
      "           9       1.00      1.00      1.00         9\n",
      "          10       1.00      0.56      0.71         9\n",
      "          11       1.00      0.22      0.36         9\n",
      "          12       0.79      0.83      0.81        18\n",
      "          13       0.78      0.78      0.78         9\n",
      "          14       0.90      1.00      0.95         9\n",
      "          15       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.78       207\n",
      "   macro avg       0.84      0.76      0.78       207\n",
      "weighted avg       0.80      0.78      0.77       207\n",
      "\n",
      "Classes : ['Hotel_info' 'acceuil' 'boiler_fixing' 'chill_production'\n",
      " 'chiller_fixing' 'cogen_fixing' 'fixing' 'get_consumption'\n",
      " 'get_elec_consumption' 'get_gaz_consumption' 'get_occupation'\n",
      " 'heat_production' 'rooms' 'temp_boiler' 'temp_chill' 'ventilation']\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:34.874699Z",
     "start_time": "2025-08-18T08:23:34.870237Z"
    }
   },
   "cell_type": "code",
   "source": "print(le.classes_)",
   "id": "deda1d768244eac8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hotel_info' 'acceuil' 'boiler_fixing' 'chill_production'\n",
      " 'chiller_fixing' 'cogen_fixing' 'fixing' 'get_consumption'\n",
      " 'get_elec_consumption' 'get_gaz_consumption' 'get_occupation'\n",
      " 'heat_production' 'rooms' 'temp_boiler' 'temp_chill' 'ventilation']\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:35.389418Z",
     "start_time": "2025-08-18T08:23:35.341964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prediction(input,model):\n",
    "    X_emb = model.encode(input, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    proba = clf_T.predict_proba(X_emb)[0]\n",
    "    return proba\n",
    "\n",
    "test = [\"comment va la ventilation ?\"]\n",
    "proba = prediction(test,model)\n",
    "print(proba)\n",
    "\n",
    "pred_class = le.classes_[proba.argmax()]\n",
    "confidence = proba.max()\n",
    "print(f\"Intent prédit : {pred_class} (confiance {confidence:.2f})\")\n",
    "\n"
   ],
   "id": "48be6d5983adf713",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0728931  0.02361585 0.12350931 0.03167968 0.05269084 0.02546408\n",
      " 0.01640139 0.01621946 0.01848779 0.02972781 0.0440317  0.04343483\n",
      " 0.05806254 0.03876899 0.03799468 0.36701796]\n",
      "Intent prédit : ventilation (confiance 0.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugom\\OneDrive\\Documents\\Git_Stage_2025_ZMH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TFIDF + transformers fréquence +semantique",
   "id": "b224d93f43a64e49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:23:47.445596Z",
     "start_time": "2025-08-18T08:23:47.397161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def prediction_T(input,model):\n",
    "    X_emb = model.encode(input, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    proba = clf_T.predict_proba(X_emb)[0]\n",
    "    return proba\n",
    "def prediction_tfidf(input):\n",
    "    X_new = vectorizer.transform(input)\n",
    "    proba = clf.predict_proba(X_new)[0]\n",
    "    return proba\n",
    "\n",
    "def prediction_tfidf_T(input,model):\n",
    "    proba_T = prediction_T(input,model)\n",
    "    proba_tfidf = prediction_tfidf(input)\n",
    "    proba = np.zeros(len(proba_T))\n",
    "    for i in range(len(proba_T)):\n",
    "        proba[i]=np.mean([proba_T[i],proba_tfidf[i]])\n",
    "    return proba\n",
    "test = [\"comment va la ventilation ?\"]\n",
    "proba = prediction_tfidf_T(test,model)\n",
    "print(proba)\n",
    "\n",
    "pred_class = le.classes_[proba.argmax()]\n",
    "confidence = proba.max()\n",
    "print(f\"Intent prédit : {pred_class} (confiance {confidence:.2f})\")\n"
   ],
   "id": "70b7192defe2239d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05859943 0.02519292 0.08860086 0.03642511 0.04589066 0.04225347\n",
      " 0.0209894  0.0184232  0.02178069 0.02547587 0.0351255  0.03610151\n",
      " 0.05925331 0.03076304 0.03036519 0.42475985]\n",
      "Intent prédit : ventilation (confiance 0.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugom\\OneDrive\\Documents\\Git_Stage_2025_ZMH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedding + SVC",
   "id": "6e9041bf0e4b2613"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:22:34.551072Z",
     "start_time": "2025-09-02T11:22:25.135412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "X_emb = model.encode(df[\"text\"], convert_to_numpy=True, normalize_embeddings=True)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"intent\"])\n"
   ],
   "id": "c6cefa32230525c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugom\\OneDrive\\Documents\\Git_Stage_2025_ZMH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:22:46.321351Z",
     "start_time": "2025-09-02T11:22:45.107327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "svm = LinearSVC(C=1.0)\n",
    "svc_cal = CalibratedClassifierCV(svm, cv=5)  # donne predict_proba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_emb, y, stratify=y, test_size=0.3, random_state=42)\n",
    "svc_cal.fit(X_train, y_train)\n",
    "y_pred = svc_cal.predict(X_test)\n",
    "joblib.dump(svc_cal, \"modele_LLM_SVC.pkl\")\n",
    "\n",
    "print(classification_report(y_test, y_pred,zero_division=0))\n",
    "print(\"Classes :\", le.classes_)"
   ],
   "id": "54c08fff7837f855",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86        21\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.80      0.87      0.83        23\n",
      "           3       0.69      0.69      0.69        13\n",
      "           4       0.68      0.68      0.68        19\n",
      "           5       0.77      0.74      0.76        23\n",
      "           6       0.73      0.89      0.80         9\n",
      "           7       0.90      1.00      0.95         9\n",
      "           8       1.00      0.89      0.94         9\n",
      "           9       1.00      1.00      1.00         9\n",
      "          10       1.00      0.56      0.71         9\n",
      "          11       0.67      0.44      0.53         9\n",
      "          12       0.79      0.83      0.81        18\n",
      "          13       0.80      0.89      0.84         9\n",
      "          14       1.00      1.00      1.00         9\n",
      "          15       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.82       207\n",
      "   macro avg       0.85      0.83      0.83       207\n",
      "weighted avg       0.82      0.82      0.82       207\n",
      "\n",
      "Classes : ['Hotel_info' 'acceuil' 'boiler_fixing' 'chill_production'\n",
      " 'chiller_fixing' 'cogen_fixing' 'fixing' 'get_consumption'\n",
      " 'get_elec_consumption' 'get_gaz_consumption' 'get_occupation'\n",
      " 'heat_production' 'rooms' 'temp_boiler' 'temp_chill' 'ventilation']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:26:36.609334Z",
     "start_time": "2025-08-18T08:26:36.567040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prediction_SVC(input,model):\n",
    "    X_emb = model.encode(input, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    proba = svc_cal.predict_proba(X_emb)[0]\n",
    "    return proba\n",
    "test = [\"comment va la ventilation ?\"]\n",
    "proba = prediction_tfidf_T(test,model)\n",
    "print(proba)\n",
    "\n",
    "pred_class = le.classes_[proba.argmax()]\n",
    "confidence = proba.max()\n",
    "print(f\"Intent prédit : {pred_class} (confiance {confidence:.2f})\")"
   ],
   "id": "7f0345629cdc8a49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05859943 0.02519292 0.08860086 0.03642511 0.04589066 0.04225347\n",
      " 0.0209894  0.0184232  0.02178069 0.02547587 0.0351255  0.03610151\n",
      " 0.05925331 0.03076304 0.03036519 0.42475985]\n",
      "Intent prédit : ventilation (confiance 0.42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugom\\OneDrive\\Documents\\Git_Stage_2025_ZMH\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:26:37.281637Z",
     "start_time": "2025-08-18T08:26:37.279666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tree_json = {\n",
    "        \"start\": \"acceuil\",\n",
    "        \"nodes\": {\n",
    "            \"acceuil\": {\"type\": \"message\",\n",
    "                        \"text\": \"\"\"### welcome to the client service, please choose an option:\n",
    "                                    * infos sur l'hotel\n",
    "                                    * fixing \"\"\",\n",
    "                        \"options\": [{\"label\": \"Hotel info\", \"next\": \"Hotel_info\"},\n",
    "                                    {\"label\": \"fixing\", \"next\": \"fixing\"}],\n",
    "                        \"on_action\": False},\n",
    "            \"Hotel_info\": {\"type\": \"message\",\n",
    "                           \"text\": \"\"\"welcom to the Informations client service\"\"\",\n",
    "                           \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"},\n",
    "                                       {\"label\": \"consumption\", \"next\": \"get_consumption\"},\n",
    "                                       {\"label\": \"occupation\", \"next\": \"get_occupation\"},\n",
    "                                       {\"label\": \"rooms\", \"next\": \"rooms\"},\n",
    "                                       {\"label\": \"temperature at the ouput off the boiler\", \"next\": \"temp_boiler\"},\n",
    "                                       {\"label\": \"temperature at the ouput off the chiller\", \"next\": \"temp_chill\"},\n",
    "                                       {\"label\": \"ventilation\", \"next\": \"ventilation\"}],\n",
    "                           \"on_action\": False},\n",
    "            \"fixing\": {\"type\": \"message\",\n",
    "                       \"text\": \"\"\"welcom to the fixing client service\"\"\",\n",
    "                       \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"},\n",
    "                                   {\"label\": \"chill production\", \"next\": \"chill_production\"},\n",
    "                                   {\"label\": \"heat production\", \"next\": \"heat_production\"}],\n",
    "                       \"on_action\": False},\n",
    "            \"ventilation\": {\"type\": \"action\",\n",
    "                            \"text\": \"welcom to the ventilation client service\",\n",
    "                            \"options\": [],\n",
    "                            \"on_action\": GPXX_check},\n",
    "            \"rooms\": {\"type\": \"form\",\n",
    "                      \"text\": \"welcom to the room client service, please enter the room\",\n",
    "                      \"options\": [],\n",
    "                      \"on_action\": room_check},\n",
    "\n",
    "            \"temp_chill\": {\"type\": \"action\",\n",
    "                           \"text\": False,\n",
    "                           \"options\": [],\n",
    "                           \"on_action\": get_temp_chill\n",
    "                           },\n",
    "            \"temp_boiler\": {\"type\": \"action\",\n",
    "                            \"text\": False,\n",
    "                            \"options\": [],\n",
    "                            \"on_action\": get_temp_boiler\n",
    "                            },\n",
    "            \"get_consumption\": {\"type\": \"message\",\n",
    "                                \"text\": \"welcom to the consumption client service\",\n",
    "                                \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"},\n",
    "                                            {\"label\": \"elec consumption\", \"next\": \"get_elec_consumption\"},\n",
    "                                            {\"label\": \"gaz consumption\", \"next\": \"get_gaz_consumption\"}],\n",
    "                                \"on_action\": False},\n",
    "            \"get_elec_consumption\": {\"type\": \"action\",\n",
    "                                     \"text\": \"welcom to the elec consumption client service\",\n",
    "                                     \"options\": [],\n",
    "                                     \"on_action\": get_elec_consumption},\n",
    "            \"get_gaz_consumption\": {\"type\": \"action\",\n",
    "                                    \"text\": \"welcom to the gaz consumption client service\",\n",
    "                                    \"options\": [],\n",
    "                                    \"on_action\": get_gaz_consumption},\n",
    "            \"get_occupation\": {\"type\": \"action\",\n",
    "                               \"text\": \"welcom to the occupation client service\",\n",
    "                               \"options\": [],\n",
    "                               \"on_action\": get_occupation},\n",
    "            \"heat_production\": {\"type\": \"message\",\n",
    "                                \"text\": \"welcom to the heat production client service\",\n",
    "                                \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"},\n",
    "                                            {\"label\": \"boiler problem\", \"next\": \"boiler_fixing\"},\n",
    "                                            {\"label\": \"cogen problem\", \"next\": \"cogen_fixing\"}],\n",
    "                                \"on_action\": False},\n",
    "            \"boiler_fixing\": {\"type\": \"message\",\n",
    "                              \"text\": \"\"\"welcom to the boiler client service\n",
    "\n",
    "                      •\tTempérature de départ est trop basse : regarder le tableau des automates (disjoncteurs ou thermique),\n",
    "                       vérifier la pression, vérifier la distribution pour s’assurer qu’il y a du débit (mais si T basse -> distribution fonctionne normalement),\n",
    "                       aller voir sur place, vérifier le gaz avec la société de maintenance\n",
    "\n",
    "\n",
    "                        o\tSolution : forcer temporairement une ou plusieurs chaudières en manuel et sur la GTC\n",
    "    \"\"\",\n",
    "                              \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"}],\n",
    "                              \"on_action\": False},\n",
    "            \"cogen_fixing\": {\"type\": \"message\",\n",
    "                             \"text\": \"\"\"welcom to the cogen client service\n",
    "                      Pas assez de demande  les ballons sont trop chauds  elle ne démarre plus\n",
    "\n",
    "    \"\"\",\n",
    "                             \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"}],\n",
    "                             \"on_action\": False},\n",
    "            \"chill_production\": {\"type\": \"message\",\n",
    "                                 \"text\": \"welcom to the chill production client service\",\n",
    "                                 \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"},\n",
    "                                             {\"label\": \"chiller problem\", \"next\": \"chiller_fixing\"}],\n",
    "                                 \"on_action\": False},\n",
    "            \"chiller_fixing\": {\"type\": \"message\",\n",
    "                               \"text\": \"\"\"welcom to the chiller client service\n",
    "                     Les tours n’ont pas assez refroidi (message : pression trop haute)\n",
    "\n",
    "\n",
    "                     Essayer de maintenir 28°C\n",
    "\n",
    "    \"\"\",\n",
    "                               \"options\": [{\"label\": \"home\", \"next\": \"acceuil\"}],\n",
    "                               \"on_action\": False},\n",
    "\n",
    "        }\n",
    "    }\n"
   ],
   "id": "91353d9ebca5f795",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T06:51:42.272725Z",
     "start_time": "2025-09-03T06:51:25.562460Z"
    }
   },
   "cell_type": "code",
   "source": "m = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
   "id": "5dd0d0d63418fab8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T06:53:56.066231Z",
     "start_time": "2025-09-03T06:53:49.024667Z"
    }
   },
   "cell_type": "code",
   "source": "m.save()",
   "id": "ff9244450dc4c1f6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9580455106b6bb2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
